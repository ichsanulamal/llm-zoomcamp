{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "# Define the local file path\n",
    "LOCAL_JSON_FILE = 'documents.json'\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "\n",
    "# Attempt to load from local file, otherwise download and save\n",
    "try:\n",
    "    with open(LOCAL_JSON_FILE, 'r', encoding='utf-8') as f:\n",
    "        documents_raw = json.load(f)\n",
    "    print(\"Loaded documents from local file.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Local file not found. Downloading...\")\n",
    "    docs_response = requests.get(docs_url)\n",
    "    docs_response.raise_for_status()\n",
    "    documents_raw = docs_response.json()\n",
    "    with open(LOCAL_JSON_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(documents_raw, f, indent=4)\n",
    "    print(\"Downloaded and saved documents locally.\")\n",
    "\n",
    "# Process the documents\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "print(\"\\nFirst document after processing:\")\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c7597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Elasticsearch!\n"
     ]
    }
   ],
   "source": [
    "# 2. Connect to Elasticsearch\n",
    "# Replace with your Elasticsearch host and port if different\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# Check if connection is successful\n",
    "if not es.ping():\n",
    "    raise ValueError(\"Connection to Elasticsearch failed!\")\n",
    "else:\n",
    "    print(\"Successfully connected to Elasticsearch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080d07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'llm_zoomcamp_documents' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# 3. Define your index name\n",
    "index_name = \"llm_zoomcamp_documents\"\n",
    "\n",
    "# 4. Optional: Define a mapping for your index\n",
    "# This helps Elasticsearch understand your data types and how to index them.\n",
    "# If you don't define this, Elasticsearch will guess.\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"text\": {\"type\": \"text\"},\n",
    "        \"section\": {\"type\": \"text\"}, # Use keyword for exact matches (e.g., filtering)\n",
    "        \"question\": {\"type\": \"text\"},\n",
    "        \"course\": {\"type\": \"keyword\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# 5. Create the index (if it doesn't exist) with the mapping\n",
    "if es.indices.exists(index=index_name):\n",
    "    print(f\"Index '{index_name}' already exists. Deleting and recreating...\")\n",
    "    es.indices.delete(index=index_name) # Be careful with this in production!\n",
    "\n",
    "es.indices.create(index=index_name, body={\"mappings\": mappings})\n",
    "print(f\"Index '{index_name}' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db2770",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "it should be .index to create index, but we can use bulk index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e99a062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed 948 documents.\n"
     ]
    }
   ],
   "source": [
    "# 6. Prepare documents for bulk indexing\n",
    "# The helpers.bulk function expects a list of dictionaries,\n",
    "# where each dictionary has at least '_index' and '_source' keys.\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": index_name,\n",
    "        \"_source\": doc\n",
    "    }\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# 7. Perform bulk indexing\n",
    "try:\n",
    "    success, failed = helpers.bulk(es, actions, index=index_name)\n",
    "    print(f\"Successfully indexed {success} documents.\")\n",
    "    if failed:\n",
    "        print(f\"Failed to index {len(failed)} documents. First 5 failures: {failed[:5]}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during bulk indexing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74898dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in 'llm_zoomcamp_documents': 948\n"
     ]
    }
   ],
   "source": [
    "# 8. Verify the count of documents\n",
    "doc_count = es.count(index=index_name)['count']\n",
    "print(f\"Total documents in '{index_name}': {doc_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe8217",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd77b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top ranking result:\n",
      "Score: 44.50556\n",
      "Question: How do I debug a docker container?\n",
      "Text: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "docker run -it --entrypoint bash <image>\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker ps (find the container-id)\n",
      "docker exec -it <container-id> bash\n",
      "(Marcos MJD)\n",
      "Course: machine-learning-zoomcamp\n"
     ]
    }
   ],
   "source": [
    "# --- Search Query ---\n",
    "query = \"How do execute a command on a Kubernetes pod?\"\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 5, # We only need the top result\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": query,\n",
    "            \"fields\": [\"question^4\", \"text\"], # question field gets a boost of 4\n",
    "            \"type\": \"best_fields\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=search_query)\n",
    "\n",
    "# Extract and print the score of the top result\n",
    "if response['hits']['hits']:\n",
    "    top_hit = response['hits']['hits'][0]\n",
    "    score = top_hit['_score']\n",
    "    print(f\"\\nTop ranking result:\")\n",
    "    print(f\"Score: {score}\")\n",
    "    print(f\"Question: {top_hit['_source'].get('question')}\")\n",
    "    print(f\"Text: {top_hit['_source'].get('text')}\")\n",
    "    print(f\"Course: {top_hit['_source'].get('course')}\")\n",
    "else:\n",
    "    print(\"No results found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c02e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.50556 {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I debug a docker container?', 'course': 'machine-learning-zoomcamp'}\n",
      "35.433445 {'text': 'Deploy and Access the Kubernetes Dashboard\\nLuke', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Kubernetes-dashboard', 'course': 'machine-learning-zoomcamp'}\n",
      "33.70974 {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I copy files from a different folder into docker containerâ€™s working directory?', 'course': 'machine-learning-zoomcamp'}\n",
      "33.2635 {'text': 'Problem description:\\nI started a web-server in terminal (command window, powershell, etc.). How can I run another python script, which makes a request to this server?\\nSolution description:\\nJust open another terminal (command window, powershell, etc.) and run a python script.\\nAlena Kniazeva', 'section': '5. Deploying Machine Learning Models', 'question': 'How to run a script while a web-server is working?', 'course': 'machine-learning-zoomcamp'}\n",
      "32.589073 {'text': \"Matplotlib has a cool method to annotate where you could provide an X,Y point and annotate with an arrow and text. For example this will show an arrow pointing to the x,y point optimal threshold.\\nplt.annotate(f'Optimal Threshold: {optimal_threshold:.2f}\\\\nOptimal F1 Score: {optimal_f1_score:.2f}',\\nxy=(optimal_threshold, optimal_f1_score),\\nxytext=(0.3, 0.5),\\ntextcoords='axes fraction',\\narrowprops=dict(facecolor='black', shrink=0.05))\\nQuinn Avila\", 'section': '4. Evaluation Metrics for Classification', 'question': 'How can I annotate a graph?', 'course': 'machine-learning-zoomcamp'}\n"
     ]
    }
   ],
   "source": [
    "result_docs = []\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    print(hit['_score'], hit['_source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22952e97",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bc0838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for: 'How do copy a file to a Docker container?' in course 'machine-learning-zoomcamp' (top 3 results):\n",
      "Course: machine-learning-zoomcamp, Question: How do I debug a docker container?, Score: 73.38676\n",
      "Course: machine-learning-zoomcamp, Question: How do I copy files from my local machine to docker container?, Score: 66.688705\n",
      "Course: machine-learning-zoomcamp, Question: How do I copy files from a different folder into docker containerâ€™s working directory?, Score: 59.812744\n"
     ]
    }
   ],
   "source": [
    "# --- NEW SEARCH QUERY ---\n",
    "query = \"How do copy a file to a Docker container?\"\n",
    "course_filter = \"machine-learning-zoomcamp\"\n",
    "num_results = 3\n",
    "\n",
    "search_query = {\n",
    "    \"size\": num_results,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": course_filter\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nSearching for: '{query}' in course '{course_filter}' (top {num_results} results):\")\n",
    "response = es.search(index=index_name, body=search_query)\n",
    "\n",
    "# Print the top results and their scores\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Course: {hit['_source']['course']}, Question: {hit['_source']['question']}, Score: {hit['_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675f0e2",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c113a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated Prompt for LLM ---\n",
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "QUESTION: How do I execute a command in a running docker container?\n",
      "\n",
      "CONTEXT:\n",
      "Q: How do I debug a docker container?\n",
      "A: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "docker run -it --entrypoint bash <image>\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker ps (find the container-id)\n",
      "docker exec -it <container-id> bash\n",
      "(Marcos MJD)\n",
      "\n",
      "Q: How do I copy files from my local machine to docker container?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "To copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\n",
      "docker cp /path/to/local/file_or_directory container_id:/path/in/container\n",
      "Hrithik Kumar Advani\n",
      "\n",
      "Q: How do I copy files from a different folder into docker containerâ€™s working directory?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\t\t\t\t\t\t\t\t\t\t\tGopakumar Gopinathan\n",
      "\n",
      "--- End of Prompt ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Build the context string\n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "context_entries = []\n",
    "for hit in response['hits']['hits']:\n",
    "    doc = hit['_source']\n",
    "    context_entries.append(context_template.format(question=doc['question'], text=doc['text']))\n",
    "\n",
    "context = \"\\n\\n\".join(context_entries)\n",
    "\n",
    "# 2. Define the main question\n",
    "question_to_llm = \"How do I execute a command in a running docker container?\"\n",
    "\n",
    "# 3. Construct the final prompt\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "final_prompt = prompt_template.format(question=question_to_llm, context=context)\n",
    "\n",
    "print(\"\\n--- Generated Prompt for LLM ---\")\n",
    "print(final_prompt)\n",
    "print(\"\\n--- End of Prompt ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a73eca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1462"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb9bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdf52ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt has 322 tokens.\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "# Calculate tokens\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(final_prompt)\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "print(f\"The prompt has {num_tokens} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56a515aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63842,\n",
       " 261,\n",
       " 4165,\n",
       " 14029,\n",
       " 29186,\n",
       " 13,\n",
       " 30985,\n",
       " 290,\n",
       " 150339,\n",
       " 4122,\n",
       " 402,\n",
       " 290,\n",
       " 31810,\n",
       " 8099,\n",
       " 591,\n",
       " 290,\n",
       " 40251,\n",
       " 7862,\n",
       " 558,\n",
       " 8470,\n",
       " 1606,\n",
       " 290,\n",
       " 19719,\n",
       " 591,\n",
       " 290,\n",
       " 31810,\n",
       " 8099,\n",
       " 1261,\n",
       " 55959,\n",
       " 290,\n",
       " 150339,\n",
       " 364,\n",
       " 107036,\n",
       " 25,\n",
       " 3253,\n",
       " 621,\n",
       " 357,\n",
       " 15792,\n",
       " 261,\n",
       " 6348,\n",
       " 306,\n",
       " 261,\n",
       " 6788,\n",
       " 62275,\n",
       " 9282,\n",
       " 1715,\n",
       " 10637,\n",
       " 50738,\n",
       " 734,\n",
       " 48,\n",
       " 25,\n",
       " 3253,\n",
       " 621,\n",
       " 357,\n",
       " 15199,\n",
       " 261,\n",
       " 62275,\n",
       " 9282,\n",
       " 3901,\n",
       " 32,\n",
       " 25,\n",
       " 41281,\n",
       " 290,\n",
       " 9282,\n",
       " 3621,\n",
       " 306,\n",
       " 25383,\n",
       " 6766,\n",
       " 326,\n",
       " 151187,\n",
       " 290,\n",
       " 7251,\n",
       " 4859,\n",
       " 11,\n",
       " 813,\n",
       " 484,\n",
       " 480,\n",
       " 13217,\n",
       " 261,\n",
       " 38615,\n",
       " 6348,\n",
       " 558,\n",
       " 68923,\n",
       " 2461,\n",
       " 533,\n",
       " 278,\n",
       " 2230,\n",
       " 7962,\n",
       " 4859,\n",
       " 38615,\n",
       " 464,\n",
       " 3365,\n",
       " 523,\n",
       " 3335,\n",
       " 290,\n",
       " 9282,\n",
       " 382,\n",
       " 4279,\n",
       " 6788,\n",
       " 11,\n",
       " 15792,\n",
       " 261,\n",
       " 6348,\n",
       " 306,\n",
       " 290,\n",
       " 4857,\n",
       " 9282,\n",
       " 734,\n",
       " 68923,\n",
       " 10942,\n",
       " 350,\n",
       " 6555,\n",
       " 290,\n",
       " 9282,\n",
       " 26240,\n",
       " 446,\n",
       " 68923,\n",
       " 25398,\n",
       " 533,\n",
       " 278,\n",
       " 464,\n",
       " 6896,\n",
       " 26240,\n",
       " 29,\n",
       " 38615,\n",
       " 198,\n",
       " 6103,\n",
       " 277,\n",
       " 10732,\n",
       " 391,\n",
       " 79771,\n",
       " 1029,\n",
       " 48,\n",
       " 25,\n",
       " 3253,\n",
       " 621,\n",
       " 357,\n",
       " 5150,\n",
       " 6291,\n",
       " 591,\n",
       " 922,\n",
       " 2698,\n",
       " 7342,\n",
       " 316,\n",
       " 62275,\n",
       " 9282,\n",
       " 3901,\n",
       " 32,\n",
       " 25,\n",
       " 1608,\n",
       " 665,\n",
       " 5150,\n",
       " 6291,\n",
       " 591,\n",
       " 634,\n",
       " 2698,\n",
       " 7342,\n",
       " 1511,\n",
       " 261,\n",
       " 91238,\n",
       " 9282,\n",
       " 2360,\n",
       " 290,\n",
       " 62275,\n",
       " 27776,\n",
       " 6348,\n",
       " 13,\n",
       " 44257,\n",
       " 1495,\n",
       " 316,\n",
       " 621,\n",
       " 480,\n",
       " 734,\n",
       " 1385,\n",
       " 5150,\n",
       " 261,\n",
       " 1974,\n",
       " 503,\n",
       " 12552,\n",
       " 591,\n",
       " 634,\n",
       " 2698,\n",
       " 7342,\n",
       " 1511,\n",
       " 261,\n",
       " 6788,\n",
       " 91238,\n",
       " 9282,\n",
       " 11,\n",
       " 481,\n",
       " 665,\n",
       " 1199,\n",
       " 290,\n",
       " 2700,\n",
       " 68923,\n",
       " 27776,\n",
       " 6348,\n",
       " 62102,\n",
       " 623,\n",
       " 9439,\n",
       " 45440,\n",
       " 382,\n",
       " 472,\n",
       " 18183,\n",
       " 734,\n",
       " 68923,\n",
       " 27776,\n",
       " 820,\n",
       " 4189,\n",
       " 72231,\n",
       " 52214,\n",
       " 51766,\n",
       " 15400,\n",
       " 35850,\n",
       " 9282,\n",
       " 1537,\n",
       " 27975,\n",
       " 4189,\n",
       " 26985,\n",
       " 190543,\n",
       " 198,\n",
       " 106096,\n",
       " 437,\n",
       " 507,\n",
       " 70737,\n",
       " 15241,\n",
       " 3048,\n",
       " 279,\n",
       " 48,\n",
       " 25,\n",
       " 3253,\n",
       " 621,\n",
       " 357,\n",
       " 5150,\n",
       " 6291,\n",
       " 591,\n",
       " 261,\n",
       " 2647,\n",
       " 15610,\n",
       " 1511,\n",
       " 62275,\n",
       " 9282,\n",
       " 802,\n",
       " 4113,\n",
       " 12552,\n",
       " 3901,\n",
       " 32,\n",
       " 25,\n",
       " 1608,\n",
       " 665,\n",
       " 5150,\n",
       " 6291,\n",
       " 591,\n",
       " 634,\n",
       " 2698,\n",
       " 7342,\n",
       " 1511,\n",
       " 261,\n",
       " 91238,\n",
       " 9282,\n",
       " 2360,\n",
       " 290,\n",
       " 62275,\n",
       " 27776,\n",
       " 6348,\n",
       " 13,\n",
       " 44257,\n",
       " 1495,\n",
       " 316,\n",
       " 621,\n",
       " 480,\n",
       " 734,\n",
       " 637,\n",
       " 290,\n",
       " 91238,\n",
       " 2318,\n",
       " 11,\n",
       " 481,\n",
       " 665,\n",
       " 3587,\n",
       " 290,\n",
       " 15610,\n",
       " 15683,\n",
       " 290,\n",
       " 6291,\n",
       " 484,\n",
       " 481,\n",
       " 1682,\n",
       " 316,\n",
       " 5150,\n",
       " 1072,\n",
       " 13,\n",
       " 623,\n",
       " 9439,\n",
       " 45440,\n",
       " 382,\n",
       " 472,\n",
       " 18183,\n",
       " 734,\n",
       " 128701,\n",
       " 9129,\n",
       " 7205,\n",
       " 8138,\n",
       " 21369,\n",
       " 17311,\n",
       " 672,\n",
       " 392,\n",
       " 13123,\n",
       " 22739,\n",
       " 9320,\n",
       " 10928,\n",
       " 69422,\n",
       " 672,\n",
       " 9633,\n",
       " 2601,\n",
       " 14973,\n",
       " 22713,\n",
       " 167296,\n",
       " 30463,\n",
       " 499,\n",
       " 137058,\n",
       " 22064]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b14ccb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided CONTEXT, I will answer your question:\n",
       "\n",
       "To execute a command in a running Docker container, you can use the following methods:\n",
       "\n",
       "1. Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
       "2. Execute a command in the specific container by using `docker ps` to find the container-id and then `docker exec -it <container-id> bash`.\n",
       "\n",
       "This will allow you to interact with the container as if it were your local machine."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama3.2:1b\",\n",
    "  messages=[\n",
    "            {\"role\": \"user\", \"content\": final_prompt}\n",
    "        ],\n",
    "        temperature=0.0, # Often good to keep low for factual retrieval\n",
    ")\n",
    "display(Markdown((response.choices[0].message.content)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
